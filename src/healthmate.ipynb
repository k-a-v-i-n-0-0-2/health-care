{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ICvDkTFTEx6-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flask in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-cors in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (2.32.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (11.3.0)\n",
      "Requirement already satisfied: ibm-watsonx-ai in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (1.3.32)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (0.28.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (2.2.3)\n",
      "Requirement already satisfied: cachetools in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (6.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (25.0)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.15.0,>=2.12.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (2.14.3)\n",
      "Requirement already satisfied: lomond in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (0.3.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-watsonx-ai) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai) (0.16.0)\n",
      "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.14.3 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.14.3)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.14.3 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.14.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (4.14.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\profe\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flask flask-cors requests pillow ibm-watsonx-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DgEGyigpDz6L"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "# IBM Watson X AI imports\n",
    "try:\n",
    "    from ibm_watsonx_ai import Credentials\n",
    "    from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "    WATSON_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WATSON_AVAILABLE = False\n",
    "    print(\"Warning: IBM Watson X AI not installed. Install with: pip install ibm-watsonx-ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u1xvg2ybFBnP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x274eb08b1f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCOQty4tD8qR"
   },
   "outputs": [],
   "source": [
    "# IBM Watson X AI Configuration - Your predefined credentials\n",
    "WATSONX_EU_APIKEY = \"grsjZnkKVEfU6O3xITUQV1pur8cY8ZOLWdk6M9kT9LUb\"\n",
    "WATSONX_EU_PROJECT_ID = \"3bb15573-631a-4c1d-9a24-41b1f50dc072\"\n",
    "WATSONX_URL = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RKBaNJXeD8tA"
   },
   "outputs": [],
   "source": [
    "class MedicalImageAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.credentials = None\n",
    "        self.models = {}\n",
    "        self.initialize_watson()\n",
    "\n",
    "    def initialize_watson(self):\n",
    "        \"\"\"Initialize Watson X AI credentials and models\"\"\"\n",
    "        if not WATSON_AVAILABLE:\n",
    "            logger.error(\"IBM Watson X AI not available\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            self.credentials = Credentials(\n",
    "                url=WATSONX_URL,\n",
    "                api_key=WATSONX_EU_APIKEY\n",
    "            )\n",
    "\n",
    "            # Initialize models\n",
    "            self.models = {\n",
    "                \"pixtral\": ModelInference(\n",
    "                    model_id=\"mistralai/pixtral-12b\",\n",
    "                    credentials=self.credentials,\n",
    "                    project_id=WATSONX_EU_PROJECT_ID,\n",
    "                    params={\"max_tokens\": 300}\n",
    "                ),\n",
    "                \"llama_vision\": ModelInference(\n",
    "                    model_id=\"meta-llama/llama-3-2-11b-vision-instruct\",\n",
    "                    credentials=self.credentials,\n",
    "                    project_id=WATSONX_EU_PROJECT_ID,\n",
    "                    params={\"max_tokens\": 300}\n",
    "                )\n",
    "            }\n",
    "\n",
    "            logger.info(\"‚úÖ Watson X AI models initialized successfully\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to initialize Watson X AI: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def encode_image_from_file(self, image_file):\n",
    "        \"\"\"Convert uploaded file to base64 encoded string\"\"\"\n",
    "        try:\n",
    "            # Read image file\n",
    "            image_data = image_file.read()\n",
    "\n",
    "            # Validate and process image\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "            # Convert to RGB if needed\n",
    "            if image.mode in ('RGBA', 'P'):\n",
    "                image = image.convert('RGB')\n",
    "\n",
    "            # Resize if too large (max 2048x2048)\n",
    "            max_size = (2048, 2048)\n",
    "            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:\n",
    "                image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Convert back to bytes\n",
    "            img_buffer = io.BytesIO()\n",
    "            image.save(img_buffer, format='JPEG', quality=85)\n",
    "            img_buffer.seek(0)\n",
    "\n",
    "            # Encode to base64\n",
    "            encoded_image = base64.b64encode(img_buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "            logger.info(f\"‚úÖ Image processed successfully - Size: {image.size}\")\n",
    "            return encoded_image\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Image processing failed: {str(e)}\")\n",
    "            raise Exception(f\"Image processing failed: {str(e)}\")\n",
    "\n",
    "    def create_analysis_message(self, prompt, encoded_image):\n",
    "        \"\"\"Create message format for Watson X AI\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"You are a medical AI assistant. Analyze this medical image and respond to: {prompt}. Provide a detailed, professional medical assessment.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def analyze_with_model(self, model_name, model, messages):\n",
    "        \"\"\"Analyze image with specific model\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"üî¨ Starting analysis with {model_name}\")\n",
    "\n",
    "            response = model.chat(messages=messages)\n",
    "\n",
    "            if response and 'choices' in response and len(response['choices']) > 0:\n",
    "                result_text = response['choices'][0]['message']['content']\n",
    "                logger.info(f\"‚úÖ {model_name} analysis completed\")\n",
    "\n",
    "                return {\n",
    "                    'status': 'success',\n",
    "                    'model_name': model_name,\n",
    "                    'response': result_text,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            else:\n",
    "                raise Exception(\"Invalid response format from model\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå {model_name} analysis failed: {str(e)}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'model_name': model_name,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "    def analyze_image(self, image_file, prompt):\n",
    "        \"\"\"Main analysis function\"\"\"\n",
    "        if not self.models:\n",
    "            raise Exception(\"Watson X AI models not initialized\")\n",
    "\n",
    "        try:\n",
    "            # Process image\n",
    "            encoded_image = self.encode_image_from_file(image_file)\n",
    "\n",
    "            # Create messages\n",
    "            messages = self.create_analysis_message(prompt, encoded_image)\n",
    "\n",
    "            # Analyze with both models\n",
    "            results = {}\n",
    "\n",
    "            for model_key, model in self.models.items():\n",
    "                model_name = \"Pixtral 12B\" if model_key == \"pixtral\" else \"Llama 3.2 11B Vision\"\n",
    "                results[model_key] = self.analyze_with_model(model_name, model, messages)\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Analysis failed: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gNqL-1qhD8vr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_watsonx_ai.client:Client successfully initialized\n",
      "INFO:httpx:HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-16&project_id=4fef3547-d708-43f0-b6a4-2deee63b75a9&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-16&project_id=4fef3547-d708-43f0-b6a4-2deee63b75a9&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "C:\\Users\\profe\\AppData\\Roaming\\Python\\Python310\\site-packages\\ibm_watsonx_ai\\foundation_models\\utils\\utils.py:436: LifecycleWarning: Model 'mistralai/pixtral-12b' is in deprecated state from 2025-07-09 until 2025-10-08. IDs of alternative models: mistralai/mistral-small-3-1-24b-instruct-2503. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warn(model_state_warning, category=LifecycleWarning)\n",
      "INFO:ibm_watsonx_ai.client:Client successfully initialized\n",
      "INFO:httpx:HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-16&project_id=4fef3547-d708-43f0-b6a4-2deee63b75a9&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "INFO:ibm_watsonx_ai.wml_resource:Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-16&project_id=4fef3547-d708-43f0-b6a4-2deee63b75a9&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "INFO:__main__:‚úÖ Watson X AI models initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = MedicalImageAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QeJMTxUwD8yR"
   },
   "outputs": [],
   "source": [
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'watson_available': WATSON_AVAILABLE,\n",
    "        'models_initialized': bool(analyzer.models)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7eEr-NRZD80x"
   },
   "outputs": [],
   "source": [
    "@app.route('/api/analyze', methods=['POST'])\n",
    "def analyze_medical_image():\n",
    "    \"\"\"Analyze medical image endpoint\"\"\"\n",
    "    try:\n",
    "        # Validate request\n",
    "        if 'image' not in request.files:\n",
    "            return jsonify({\n",
    "                'status': 'error',\n",
    "                'error': 'No image file provided'\n",
    "            }), 400\n",
    "\n",
    "        if 'prompt' not in request.form:\n",
    "            return jsonify({\n",
    "                'status': 'error',\n",
    "                'error': 'No analysis prompt provided'\n",
    "            }), 400\n",
    "\n",
    "        image_file = request.files['image']\n",
    "        prompt = request.form['prompt']\n",
    "\n",
    "        # Validate file\n",
    "        if image_file.filename == '':\n",
    "            return jsonify({\n",
    "                'status': 'error',\n",
    "                'error': 'No image file selected'\n",
    "            }), 400\n",
    "\n",
    "        # Check file type\n",
    "        allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'webp'}\n",
    "        file_extension = image_file.filename.rsplit('.', 1)[1].lower()\n",
    "\n",
    "        if file_extension not in allowed_extensions:\n",
    "            return jsonify({\n",
    "                'status': 'error',\n",
    "                'error': f'Unsupported file type. Allowed: {\", \".join(allowed_extensions)}'\n",
    "            }), 400\n",
    "\n",
    "        logger.info(f\"üì§ Received analysis request: {prompt[:50]}...\")\n",
    "\n",
    "        # Analyze image\n",
    "        results = analyzer.analyze_image(image_file, prompt)\n",
    "\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'results': results,\n",
    "            'prompt': prompt,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Analysis endpoint error: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "\n",
    "        return jsonify({\n",
    "            'status': 'error',\n",
    "            'error': str(e),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x5c7lmJ_D84N"
   },
   "outputs": [],
   "source": [
    "@app.route('/api/models', methods=['GET'])\n",
    "def get_models():\n",
    "    \"\"\"Get available models information\"\"\"\n",
    "    models_info = {\n",
    "        'pixtral': {\n",
    "            'name': 'Pixtral 12B',\n",
    "            'description': 'Mistral AI vision model specialized in image analysis',\n",
    "            'capabilities': ['Medical imaging', 'General image analysis', 'Detailed descriptions']\n",
    "        },\n",
    "        'llama_vision': {\n",
    "            'name': 'Llama 3.2 11B Vision',\n",
    "            'description': 'Meta\\'s vision-language model for comprehensive analysis',\n",
    "            'capabilities': ['Medical assessment', 'Multi-modal understanding', 'Detailed reasoning']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return jsonify({\n",
    "        'status': 'success',\n",
    "        'models': models_info,\n",
    "        'available': bool(analyzer.models),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jiA411cvEsPM"
   },
   "outputs": [],
   "source": [
    "@app.errorhandler(413)\n",
    "def too_large(e):\n",
    "    return jsonify({\n",
    "        'status': 'error',\n",
    "        'error': 'File too large. Maximum size is 16MB.'\n",
    "    }), 413\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def internal_error(e):\n",
    "    return jsonify({\n",
    "        'status': 'error',\n",
    "        'error': 'Internal server error occurred.'\n",
    "    }), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t_LaL3yEsRf",
    "outputId": "52e515ee-b83f-46e5-c7d6-fa5eda0b2882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üè• HealthMate Medical Image Analysis API\n",
      "============================================================\n",
      "üì° Server starting on http://localhost:5000\n",
      "üî¨ Watson X AI Available: True\n",
      "ü§ñ Models Initialized: True\n",
      "============================================================\n",
      "\n",
      "üìã Available Endpoints:\n",
      "  GET  /api/health     - Health check\n",
      "  POST /api/analyze    - Analyze medical image\n",
      "  POST /api/chat       - Text-only chat\n",
      "  GET  /api/models     - Get model information\n",
      "\n",
      "üöÄ Ready to analyze medical images!\n",
      "============================================================\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.164:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\profe\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üè• HealthMate Medical Image Analysis API\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üì° Server starting on http://localhost:5000\")\n",
    "    print(f\"üî¨ Watson X AI Available: {WATSON_AVAILABLE}\")\n",
    "    print(f\"ü§ñ Models Initialized: {bool(analyzer.models)}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüìã Available Endpoints:\")\n",
    "    print(\"  GET  /api/health     - Health check\")\n",
    "    print(\"  POST /api/analyze    - Analyze medical image\")\n",
    "    print(\"  POST /api/chat       - Text-only chat\")\n",
    "    print(\"  GET  /api/models     - Get model information\")\n",
    "    print(\"\\nüöÄ Ready to analyze medical images!\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    # Configure for production\n",
    "    app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size\n",
    "\n",
    "    app.run(\n",
    "        host='0.0.0.0',\n",
    "        port=5000,\n",
    "        debug=True,\n",
    "        threaded=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DP6zrjMPF3IU"
   },
   "source": [
    "# üè• HealthMate Medical Image Analysis API\n",
    "\n",
    "A Flask-based REST API that leverages IBM Watson X AI's vision models to analyze medical images. The system uses multiple AI models (Pixtral 12B and Llama 3.2 11B Vision) to provide comprehensive medical image analysis and health consultations.\n",
    "\n",
    "## üåü Features\n",
    "\n",
    "- **Multi-Model Analysis**: Uses both Mistral AI's Pixtral 12B and Meta's Llama 3.2 11B Vision models\n",
    "- **Medical Image Processing**: Supports various image formats (PNG, JPG, JPEG, GIF, BMP, WebP)\n",
    "- **Intelligent Image Preprocessing**: Automatic resizing, format conversion, and optimization\n",
    "- **RESTful API**: Clean, well-documented endpoints for easy integration\n",
    "- **Health Check Monitoring**: Built-in health monitoring and status endpoints\n",
    "- **CORS Enabled**: Cross-origin resource sharing for web applications\n",
    "- **Error Handling**: Comprehensive error handling and logging\n",
    "- **File Size Management**: Configurable file size limits (16MB default)\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- IBM Watson X AI account and credentials\n",
    "- Required Python packages (see Installation)\n",
    "\n",
    "### Installation\n",
    "\n",
    "1. **Clone the repository**\n",
    "   ```bash\n",
    "   git clone <repository-url>\n",
    "   cd healthmate-api\n",
    "   ```\n",
    "\n",
    "2. **Install dependencies**\n",
    "   ```bash\n",
    "   pip install flask flask-cors requests pillow ibm-watsonx-ai\n",
    "   ```\n",
    "\n",
    "3. **Configure credentials**\n",
    "   Update the Watson X AI credentials in the code:\n",
    "   ```python\n",
    "   WATSONX_EU_APIKEY = \"your-api-key-here\"\n",
    "   WATSONX_EU_PROJECT_ID = \"your-project-id-here\"\n",
    "   WATSONX_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "   ```\n",
    "\n",
    "4. **Run the application**\n",
    "   ```bash\n",
    "   python app.py\n",
    "   ```\n",
    "\n",
    "The API will be available at `http://localhost:5000`\n",
    "\n",
    "## üìã API Endpoints\n",
    "\n",
    "### üîç Health Check\n",
    "```http\n",
    "GET /api/health\n",
    "```\n",
    "Returns server status and model availability.\n",
    "\n",
    "**Response:**\n",
    "```json\n",
    "{\n",
    "  \"status\": \"healthy\",\n",
    "  \"timestamp\": \"2024-08-04T10:30:00.000Z\",\n",
    "  \"watson_available\": true,\n",
    "  \"models_initialized\": true\n",
    "}\n",
    "```\n",
    "\n",
    "### üî¨ Analyze Medical Image\n",
    "```http\n",
    "POST /api/analyze\n",
    "```\n",
    "Analyzes medical images using both AI models.\n",
    "\n",
    "**Parameters:**\n",
    "- `image` (file): Medical image file\n",
    "- `prompt` (string): Analysis question/prompt\n",
    "\n",
    "**Example Request:**\n",
    "```bash\n",
    "curl -X POST \\\n",
    "  http://localhost:5000/api/analyze \\\n",
    "  -F \"image=@chest_xray.jpg\" \\\n",
    "  -F \"prompt=What abnormalities can you detect in this chest X-ray?\"\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```json\n",
    "{\n",
    "  \"status\": \"success\",\n",
    "  \"results\": {\n",
    "    \"pixtral\": {\n",
    "      \"status\": \"success\",\n",
    "      \"model_name\": \"Pixtral 12B\",\n",
    "      \"response\": \"Analysis result from Pixtral model...\",\n",
    "      \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "    },\n",
    "    \"llama_vision\": {\n",
    "      \"status\": \"success\",\n",
    "      \"model_name\": \"Llama 3.2 11B Vision\",\n",
    "      \"response\": \"Analysis result from Llama model...\",\n",
    "      \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "    }\n",
    "  },\n",
    "  \"prompt\": \"What abnormalities can you detect in this chest X-ray?\",\n",
    "  \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "### üí¨ Chat Endpoint\n",
    "```http\n",
    "POST /api/chat\n",
    "```\n",
    "Text-based health consultation endpoint.\n",
    "\n",
    "**Request Body:**\n",
    "```json\n",
    "{\n",
    "  \"message\": \"What are the symptoms of pneumonia?\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```json\n",
    "{\n",
    "  \"status\": \"success\",\n",
    "  \"response\": \"Health guidance and recommendations...\",\n",
    "  \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "### ü§ñ Models Information\n",
    "```http\n",
    "GET /api/models\n",
    "```\n",
    "Returns information about available AI models.\n",
    "\n",
    "**Response:**\n",
    "```json\n",
    "{\n",
    "  \"status\": \"success\",\n",
    "  \"models\": {\n",
    "    \"pixtral\": {\n",
    "      \"name\": \"Pixtral 12B\",\n",
    "      \"description\": \"Mistral AI vision model specialized in image analysis\",\n",
    "      \"capabilities\": [\"Medical imaging\", \"General image analysis\", \"Detailed descriptions\"]\n",
    "    },\n",
    "    \"llama_vision\": {\n",
    "      \"name\": \"Llama 3.2 11B Vision\",\n",
    "      \"description\": \"Meta's vision-language model for comprehensive analysis\",\n",
    "      \"capabilities\": [\"Medical assessment\", \"Multi-modal understanding\", \"Detailed reasoning\"]\n",
    "    }\n",
    "  },\n",
    "  \"available\": true,\n",
    "  \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "## üñºÔ∏è Supported Image Formats\n",
    "\n",
    "- **PNG** - Portable Network Graphics\n",
    "- **JPG/JPEG** - Joint Photographic Experts Group\n",
    "- **GIF** - Graphics Interchange Format\n",
    "- **BMP** - Bitmap Image File\n",
    "- **WebP** - Web Picture format\n",
    "\n",
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "### File Size Limits\n",
    "```python\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB\n",
    "```\n",
    "\n",
    "### Image Processing\n",
    "- **Maximum Resolution**: 2048x2048 pixels\n",
    "- **Auto-conversion**: RGBA and P mode images converted to RGB\n",
    "- **Compression**: JPEG quality set to 85%\n",
    "- **Format**: All images converted to JPEG for processing\n",
    "\n",
    "### AI Model Parameters\n",
    "```python\n",
    "params = {\"max_tokens\": 300}\n",
    "```\n",
    "\n",
    "## üîß Development\n",
    "\n",
    "### Running in Development Mode\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "The server runs with:\n",
    "- **Host**: 0.0.0.0 (accessible from any IP)\n",
    "- **Port**: 5000\n",
    "- **Debug**: True\n",
    "- **Threading**: Enabled\n",
    "\n",
    "### Jupyter Notebook\n",
    "For development and testing, you can use the provided Jupyter notebook version:\n",
    "1. Open `healthmate_notebook.ipynb`\n",
    "2. Run cells sequentially\n",
    "3. Test individual components\n",
    "\n",
    "### Logging\n",
    "The application uses Python's logging module with INFO level. Logs include:\n",
    "- Request processing\n",
    "- Image analysis progress  \n",
    "- Error tracking\n",
    "- Model performance\n",
    "\n",
    "### Project Structure\n",
    "```\n",
    "healthmate-api/\n",
    "‚îú‚îÄ‚îÄ app.py                 # Main Flask application\n",
    "‚îú‚îÄ‚îÄ healthmate_notebook.ipynb  # Jupyter notebook version\n",
    "‚îú‚îÄ‚îÄ README.md             # This file\n",
    "‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies\n",
    "‚îî‚îÄ‚îÄ tests/               # Test files (optional)\n",
    "```\n",
    "\n",
    "## üõ†Ô∏è Error Handling\n",
    "\n",
    "The API handles various error scenarios:\n",
    "\n",
    "### Common Errors\n",
    "- **400**: Bad Request (missing image/prompt)\n",
    "- **413**: File too large (>16MB)\n",
    "- **500**: Internal server error\n",
    "\n",
    "### Error Response Format\n",
    "```json\n",
    "{\n",
    "  \"status\": \"error\",\n",
    "  \"error\": \"Error description\",\n",
    "  \"timestamp\": \"2024-08-04T10:30:00.000Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "## üîê Security Considerations\n",
    "\n",
    "1. **API Keys**: Keep Watson X AI credentials secure\n",
    "2. **File Validation**: Only accept valid image formats\n",
    "3. **Size Limits**: Prevent large file uploads\n",
    "4. **CORS**: Configure appropriately for production\n",
    "5. **Input Sanitization**: Validate all user inputs\n",
    "\n",
    "## üìä Usage Examples\n",
    "\n",
    "### Python Client Example\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Health check\n",
    "response = requests.get('http://localhost:5000/api/health')\n",
    "print(response.json())\n",
    "\n",
    "# Image analysis\n",
    "with open('medical_image.jpg', 'rb') as f:\n",
    "    files = {'image': f}\n",
    "    data = {'prompt': 'Analyze this medical image'}\n",
    "    response = requests.post('http://localhost:5000/api/analyze',\n",
    "                           files=files, data=data)\n",
    "    print(response.json())\n",
    "```\n",
    "\n",
    "### JavaScript/Web Example\n",
    "```javascript\n",
    "const formData = new FormData();\n",
    "formData.append('image', imageFile);\n",
    "formData.append('prompt', 'What do you see in this X-ray?');\n",
    "\n",
    "fetch('/api/analyze', {\n",
    "    method: 'POST',\n",
    "    body: formData\n",
    "})\n",
    ".then(response => response.json())\n",
    ".then(data => console.log(data));\n",
    "```\n",
    "\n",
    "### cURL Example\n",
    "```bash\n",
    "# Health check\n",
    "curl http://localhost:5000/api/health\n",
    "\n",
    "# Image analysis\n",
    "curl -X POST \\\n",
    "  -F \"image=@sample.jpg\" \\\n",
    "  -F \"prompt=Analyze this medical image\" \\\n",
    "  http://localhost:5000/api/analyze\n",
    "\n",
    "# Chat\n",
    "curl -X POST \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"message\":\"What are COVID-19 symptoms?\"}' \\\n",
    "  http://localhost:5000/api/chat\n",
    "```\n",
    "\n",
    "## üöÄ Production Deployment\n",
    "\n",
    "### Environment Variables\n",
    "For production, use environment variables for sensitive data:\n",
    "```bash\n",
    "export WATSONX_API_KEY=\"your-api-key\"\n",
    "export WATSONX_PROJECT_ID=\"your-project-id\"\n",
    "export WATSONX_URL=\"your-watson-url\"\n",
    "```\n",
    "\n",
    "### WSGI Server\n",
    "Use a production WSGI server like Gunicorn:\n",
    "```bash\n",
    "pip install gunicorn\n",
    "gunicorn -w 4 -b 0.0.0.0:5000 app:app\n",
    "```\n",
    "\n",
    "### Docker Deployment\n",
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "EXPOSE 5000\n",
    "CMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:5000\", \"app:app\"]\n",
    "```\n",
    "\n",
    "## üìù Requirements\n",
    "\n",
    "Create a `requirements.txt` file:\n",
    "```txt\n",
    "Flask==2.3.3\n",
    "Flask-CORS==4.0.0\n",
    "requests==2.31.0\n",
    "Pillow==10.0.1\n",
    "ibm-watsonx-ai==1.0.0\n",
    "```\n",
    "\n",
    "## ü§ù Contributing\n",
    "\n",
    "1. Fork the repository\n",
    "2. Create a feature branch\n",
    "3. Make your changes\n",
    "4. Add tests if applicable\n",
    "5. Submit a pull request\n",
    "\n",
    "## üìÑ License\n",
    "\n",
    "This project is licensed under the MIT License - see the LICENSE file for details.\n",
    "\n",
    "## ‚ö†Ô∏è Disclaimer\n",
    "\n",
    "This tool is for educational and research purposes only. It should not be used as a substitute for professional medical advice, diagnosis, or treatment. Always consult with qualified healthcare professionals for medical concerns.\n",
    "\n",
    "## üìû Support\n",
    "\n",
    "For support and questions:\n",
    "- Create an issue in the repository\n",
    "- Check the documentation\n",
    "- Review the API responses for error details\n",
    "\n",
    "## üîÑ Version History\n",
    "\n",
    "- **v1.0.0**: Initial release with dual model support\n",
    "- Multi-format image support\n",
    "- RESTful API implementation\n",
    "- Comprehensive error handling\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ‚ù§Ô∏è using Flask and IBM Watson X AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5WKF6ZPEsU8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnPAsLSgVfpktNoD0TflzW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
